import json
import base64
from io import BytesIO
import time
import os
import sys
import shutil
from openai import AzureOpenAI

client = AzureOpenAI(
    azure_endpoint="https://ura-gpt4-v.openai.azure.com/",
    api_version="2023-07-01-preview",
    api_key="3cb748f82bb04208aa84734bae93959d"
)

GPT4V = [
    {
        'key': "3cb748f82bb04208aa84734bae93959d",
        'endpoint': "https://ura-gpt4-v.openai.azure.com/openai/deployments/gpt4-v/chat/completions?api-version=2023-07-01-preview"
    },
    {
        'key': "608425edbd604db88f2f62967e599077",
        'endpoint': "https://ura-gpt4-v-1.openai.azure.com/openai/deployments/gpt4-v/chat/completions?api-version=2023-07-01-preview"
    },
    {
        # This api is slow
        'key': "f836e2c8914e4fdb9f3270fde74068bd",
        'endpoint': "https://ura-gpt4-v-2.openai.azure.com/openai/deployments/ura-gpt4-v/chat/completions?api-version=2023-07-01-preview"
    }
]

def getResponeFromGPT4V(target, image=None):
    """
    Retrieves a response from the GPT4-Vision multimodal model based on the provided target prompt and optional image. 

    Parameters:
    - target (str): The user prompt to be used as input to the model. It typically includes a request for evaluation along with a description.
    - image (str, optional): A base64 encoded image to be evaluated alongside the target prompt. If provided, the model will assess whether the image aligns with the description in the target.

    Returns:
    - str: A response generated by the model, indicating its evaluation based on the input target prompt and image.
    """
    if image:
        payload = {
            "messages": [
                {
                    "role": "system",
                    "content": [
                        {
                            "type": "text",
                            "text": "You are an AI assistant that helps people find information."
                        }
                    ]
                },
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{image}"
                            }
                        },
                        {
                            "type": "text",
                            "text": target
                        }
                    ]
                }
            ],
            "temperature": 0.7,
            "top_p": 0.95,
            "max_tokens": 800
        }
        message = "[Evaluating]"
        
    else:
        payload = {
            "messages": [
                {
                    "role": "system",
                    "content": [
                        {
                            "type": "text",
                            "text": "You are an AI assistant that helps people find information."
                        }
                    ]
                },
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": target
                        }
                    ]
                }
            ],
            "temperature": 0.7,
            "top_p": 0.95,
            "max_tokens": 800
        }
        message = "[Improving prompt]"
    
    n = randint(2) # third API is slow so use just the first two.
        
    headers = {
        "Content-Type": "application/json",
        "api-key": GPT4V[n]['key'],
    }

    print(f"\t{message}(using api [{n+1}])...")
    # print(target)
    start_time = time.time()
    
    # try:
    gptResponse = requests.post(GPT4V[n]['endpoint'], headers=headers, json=payload)
    # Will raise an HTTPError if the HTTP request returned an unsuccessful status code
    gptResponse.raise_for_status()
    # except requests.RequestException as e:
    #     raise SystemExit(f"Failed to make the request. Error: {e}")

    # Handle the response as needed (e.g., print or process)
    # print(response.json()['choices'][0]['message']['content'])
    # gptResponse = requests.post(GPT4V_ENDPOINT, headers=headers, json=payload)
    # print(llavaResponse.text)
        
    gptResultMessage = gptResponse.json()['choices'][0]['message']['content']
    process_time = time.time() - start_time
    print(f"\t[Result] in {process_time:0.1f} secs: ", gptResultMessage)
    return gptResultMessage, process_time


def getResponeFromGPT4(target):
    message_text = [{"role": "system", "content": "You are an AI assistant that helps people find information."}, {
    "role": "user", "content": target}]
    message = "[Processing]"

    print(f"\t{message}...")
    # print(target)
    start_time = time.time()
    gptResponse = client.chat.completions.create(model="gpt4",
        messages=message_text,
        temperature=0.7,
        max_tokens=800,
        top_p=0.95,
        frequency_penalty=0,
        presence_penalty=0,
        stop=None
    )

    # Handle the response as needed (e.g., print or process)
    # print(response.json()['choices'][0]['message']['content'])
    # gptResponse = requests.post(GPT4V_ENDPOINT, headers=headers, json=payload)
    # print(llavaResponse.text)
        
    gptResultMessage = gptResponse.choices[0].message.content
    process_time = time.time() - start_time
    print(f"\t[Result] in {process_time:0.1f} secs: ", gptResultMessage)
    return gptResultMessage, process_time

res = getResponeFromGPT4("A duck playing with cats, how to buy a duck")
print(res)